{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7501750c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from src import util\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fe84b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_messages, train_labels = util.load_spam_dataset('data/ds6_train.tsv')\n",
    "val_messages, val_labels = util.load_spam_dataset('data/ds6_val.tsv')\n",
    "test_messages, test_labels = util.load_spam_dataset('data/ds6_test.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30a4da00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "4457\n",
      "THANX 4 PUTTIN DA FONE DOWN ON ME!!\n",
      "\n",
      "\n",
      "[0 0 0 ... 0 0 0]\n",
      "<class 'numpy.ndarray'>\n",
      "4457\n",
      "0\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "print(type(train_messages))\n",
    "print(len(train_messages))\n",
    "print(train_messages[0])\n",
    "\n",
    "print('\\n')\n",
    "print(train_labels)\n",
    "print(type(train_labels))\n",
    "print(len(train_labels))\n",
    "print(train_labels[0])\n",
    "print(np.unique(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8598e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(message):\n",
    "    \"\"\"Get the normalized list of words from a message string.\n",
    "\n",
    "    This function should split a message into words, normalize them, and return\n",
    "    the resulting list. For splitting, you should split on spaces. For normalization,\n",
    "    you should convert everything to lowercase.\n",
    "\n",
    "    Args:\n",
    "        message: A string containing an SMS message\n",
    "\n",
    "    Returns:\n",
    "       The list of normalized words from the message.\n",
    "    \"\"\"\n",
    "    norm_sentence = message.lower()\n",
    "    norm_words = norm_sentence.split(' ') # Alert-1: this does not get rid of punctuation marks\n",
    "    \n",
    "    return norm_words\n",
    "\n",
    "\n",
    "def create_dictionary(messages):\n",
    "    \"\"\"Create a dictionary mapping words to integer indices.\n",
    "\n",
    "    This function should create a dictionary of word to indices using the provided\n",
    "    training messages. Use get_words to process each message. \n",
    "\n",
    "    Rare words are often not useful for modeling. Please only add words to the dictionary\n",
    "    if they occur in at least five messages.\n",
    "\n",
    "    Args:\n",
    "        messages: A list of strings containing SMS messages\n",
    "\n",
    "    Returns:\n",
    "        A python dict mapping words to integers.\n",
    "    \"\"\"\n",
    "    words_dict = {}\n",
    "    all_words = [] # collecting all words for counting including repition\n",
    "    final_dict = {}\n",
    "    \n",
    "    # step-1: gather all words \n",
    "    for message in messages:   \n",
    "        words = get_words(message)\n",
    "        for word in words:\n",
    "            all_words.append(word)\n",
    "            \n",
    "    # Step-2: initalise dictionary with zero values\n",
    "    \n",
    "    for word in all_words:\n",
    "        words_dict[word] = 0\n",
    "        \n",
    "    # Step-3: update word count in dictionary \n",
    "    \n",
    "    for word in all_words:\n",
    "        words_dict[word]+=1\n",
    "        \n",
    "    # step-5: get words whose key value is greater than or equal to 5\n",
    "    \n",
    "    mappping_counter = 0\n",
    "    for key in words_dict.keys():\n",
    "        if words_dict[key]>=5:\n",
    "            #final_dict[key] = words_dict[key] # Alert-2: Does not perform laplace smoothing yet\n",
    "            final_dict[key] = mappping_counter  # Alert-3: not indexed alphabateically\n",
    "            mappping_counter+=1\n",
    "    \n",
    "        \n",
    "    return final_dict\n",
    "        \n",
    "    \n",
    "def transform_text(messages, word_dictionary):\n",
    "    \"\"\"Transform a list of text messages into a numpy array for further processing.\n",
    "\n",
    "    This function should create a numpy array that contains the number of times each word\n",
    "    appears in each message. Each row in the resulting array should correspond to each \n",
    "    message and each column should correspond to a word.\n",
    "\n",
    "    Use the provided word dictionary to map words to column indices. Ignore words that \n",
    "    are not present in the dictionary. Use get_words to get the words for a message.\n",
    "\n",
    "    Args:\n",
    "        messages: A list of strings where each string is an SMS message.\n",
    "        word_dictionary: A python dict mapping words to integers.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array marking the words present in each message.\n",
    "    \"\"\"\n",
    "    # m rows x n columns\n",
    "    m = len(messages)            \n",
    "    n = len(word_dictionary.keys())\n",
    "    \n",
    "    my_array = np.zeros((m,n))\n",
    "    \n",
    "    for i in range(len(messages)):\n",
    "        message = messages[i]\n",
    "        words = get_words(message)\n",
    "        for word in words:\n",
    "            if word in word_dictionary.keys():\n",
    "                my_array[i][word_dictionary[word]]+=1\n",
    "    \n",
    "    return my_array\n",
    "\n",
    "\n",
    "\n",
    "def fit_naive_bayes_model(matrix, labels):\n",
    "    \"\"\"Fit a naive bayes model.\n",
    "\n",
    "    This function should fit a Naive Bayes model given a training matrix and labels.\n",
    "\n",
    "    The function should return the state of that model.\n",
    "\n",
    "    Feel free to use whatever datatype you wish for the state of the model.\n",
    "\n",
    "    Args:\n",
    "        matrix: A numpy array containing word counts for the training data\n",
    "        labels: The binary (0 or 1) labels for that training data\n",
    "\n",
    "    Returns: The trained model\n",
    "    \n",
    "    \"\"\"\n",
    "    # Alert:5 - Resolved - Laplace smoothing done\n",
    "\n",
    "    \n",
    "    mask1 = np.where(labels == 1)\n",
    "    mask2 = np.where(labels == 0)\n",
    "    \n",
    "    spam_emails_array = matrix[mask1]\n",
    "    nonspam_emails_array = matrix[mask2]\n",
    "    \n",
    "    spam_num = spam_emails_array.shape[0]\n",
    "    nonspam_num = nonspam_emails_array.shape[0]\n",
    "    \n",
    "    phy_spam = spam_num/labels.shape[0]\n",
    "    phy_nonspam = 1-phy_spam    \n",
    "    \n",
    "    num_x_spam = np.sum(spam_emails_array, axis=0) # sum of a word x in all spam emails\n",
    "    num_x_spam +=1 # laplace smoothing\n",
    "    all_spam_words = np.sum(np.sum(spam_emails_array, axis=1)) # All words in spam emails\n",
    "    all_spam_words += matrix.shape[1] # laplace smoothing\n",
    "    \n",
    "    p_x_spam = num_x_spam/all_spam_words # p(x|y=1)\n",
    "    \n",
    "    num_x_nonspam = np.sum(nonspam_emails_array, axis=0) # sum of a word x in all non-spam emails\n",
    "    num_x_nonspam +=1 # laplace smoothing\n",
    "    all_nonspam_words = np.sum(np.sum(nonspam_emails_array, axis=1)) # All words in non-spam emails\n",
    "    all_nonspam_words += matrix.shape[1] # laplace smoothing\n",
    "    p_x_nonspam = num_x_nonspam/all_nonspam_words # p(x|y=0)\n",
    "\n",
    "    \n",
    "    return phy_spam, phy_nonspam, p_x_spam, p_x_nonspam\n",
    "\n",
    "\n",
    "def predict_from_naive_bayes_model(phy_spam, phy_nonspam, p_x_spam, p_x_nonspam, matrix):\n",
    "    \"\"\"Use a Naive Bayes model to compute predictions for a target matrix.\n",
    "\n",
    "    This function should be able to predict on the models that fit_naive_bayes_model\n",
    "    outputs.\n",
    "\n",
    "    Args:\n",
    "        model: A trained model from fit_naive_bayes_model\n",
    "        matrix: A numpy array containing word counts\n",
    "\n",
    "    Returns: A numpy array containg the predictions from the model\n",
    "    \"\"\"\n",
    "    p_spam = np.zeros((matrix.shape[0]))\n",
    "    \n",
    "    # iterate message-wise\n",
    "    for i in range(matrix.shape[0]):\n",
    "        message = matrix[i]\n",
    "        words_mask = np.where(message > 0) # find indexes of words that appear in the email\n",
    "        all_p_x_spam = p_x_spam[words_mask]  #p(x1|y=1), p(x5|y=1), p(x8|y=1), .....\n",
    "        pi_x_spam = np.prod(all_p_x_spam[:]) # p(x1|y=1)*p(x5|y=1)*p(x8|y=1)*.....\n",
    "        all_p_x_nonspam = p_x_nonspam[words_mask]  #p(x1|y=0), p(x5|y=0), p(x8|y=0), .....\n",
    "        pi_x_nonspam = np.prod(all_p_x_nonspam[:]) # p(x1|y=0)*p(x5|y=0)*p(x8|y=0)*.....\n",
    "        \n",
    "        p_spam[i] = pi_x_spam * phy_spam/ (pi_x_spam * phy_spam + pi_x_nonspam * phy_nonspam)\n",
    "        \n",
    "    return p_spam\n",
    "        \n",
    "    \n",
    "def NB_accuracy(labels, preds):\n",
    "    true_spam_ids = np.where(labels==1)\n",
    "    pred_spam_ids = np.where(preds>=0.5)\n",
    "    \n",
    "    true_nonspam_ids = np.where(labels==0)\n",
    "    pred_nonspam_ids = np.where(preds<0.5)\n",
    "    \n",
    "    true_spam_set  = set(true_spam_ids[0])\n",
    "    pred_spam_set = set(pred_spam_ids[0])\n",
    "    true_nonspam_set = set(true_nonspam_ids[0])\n",
    "    pred_nonspam_set = set(pred_nonspam_ids[0])\n",
    "    \n",
    "    TP = len(true_spam_set.intersection(pred_spam_set))\n",
    "    TN = len(true_nonspam_set.intersection(pred_nonspam_set))\n",
    "    \n",
    "    accuracy = np.round((TP+TN)*100/(len(true_spam_set)+len(true_nonspam_set)),4)\n",
    "    \n",
    "    return accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "036837e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in dictionary:  1758\n",
      "(4457, 1758)\n",
      "first 5 message:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Train labels:  (4457,)  labels:  [0 0 0 ... 0 0 0]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Fitting on Training data\n",
      "Train accuracy:  98.3621 %\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Predicting on Validation data\n",
      "Val accuracy:  98.2047 %\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Predicting on Testing data\n",
      "Test accuracy:  97.8495 %\n"
     ]
    }
   ],
   "source": [
    "train_dict = create_dictionary(train_messages); print('Total words in dictionary: ', len(train_dict.keys()))\n",
    "train_array = transform_text(train_messages, train_dict); print(train_array.shape); print('first 5 message: ', train_array[:5,:])\n",
    "\n",
    "print('Train labels: ',train_labels.shape, ' labels: ', train_labels)\n",
    "\n",
    "print('\\n\\n\\n\\nFitting on Training data')\n",
    "phy_spam, phy_nonspam, p_x_spam, p_x_nonspam = fit_naive_bayes_model(train_array, train_labels)\n",
    "p_spam = predict_from_naive_bayes_model(phy_spam, phy_nonspam, p_x_spam, p_x_nonspam, train_array)\n",
    "train_accuracy = NB_accuracy(train_labels, p_spam)\n",
    "print('Train accuracy: ', train_accuracy,'%')\n",
    "\n",
    "\n",
    "print('\\n\\n\\n\\nPredicting on Validation data')\n",
    "val_array = transform_text(val_messages, train_dict)\n",
    "p_spam = predict_from_naive_bayes_model(phy_spam, phy_nonspam, p_x_spam, p_x_nonspam, val_array)\n",
    "val_accuracy = NB_accuracy(val_labels, p_spam)\n",
    "print('Val accuracy: ', val_accuracy,'%')\n",
    "\n",
    "\n",
    "print('\\n\\n\\n\\nPredicting on Testing data')\n",
    "test_array = transform_text(test_messages, train_dict)\n",
    "p_spam = predict_from_naive_bayes_model(phy_spam, phy_nonspam, p_x_spam, p_x_nonspam, test_array)\n",
    "test_accuracy = NB_accuracy(test_labels, p_spam)\n",
    "print('Test accuracy: ', test_accuracy,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "032f282d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_five_naive_bayes_words(phy_spam, phy_nonspam, p_x_spam, p_x_nonspam, dictionary):\n",
    "    \n",
    "    \n",
    "    my_probs = np.log(p_x_spam) - np.log(p_x_nonspam) # Alert-6: Here we have to sort after taking difference. \n",
    "    # Without difference and filtering just by which word appear most in spam email won't give accurate results at all. \n",
    "    # Because, in spam email word like 'you' can appear the most but we want to find the relative proportion of word in \n",
    "    # spam email and non-spam emails. \n",
    "    \n",
    "    top_5_words_ids  = np.argsort(my_probs)[-5:]\n",
    "    \n",
    "    reverse_dict = {value: key for key, value in dictionary.items()}\n",
    "    \n",
    "    counter = 0\n",
    "    for idx in top_5_words_ids:\n",
    "        print('Top-',5-counter, ' word is : ', reverse_dict[idx] )\n",
    "        counter+=1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b2facad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top- 5  word is :  urgent!\n",
      "Top- 4  word is :  tone\n",
      "Top- 3  word is :  prize\n",
      "Top- 2  word is :  won\n",
      "Top- 1  word is :  claim\n"
     ]
    }
   ],
   "source": [
    "phy_spam, phy_nonspam, p_x_spam, p_x_nonspam = fit_naive_bayes_model(train_array, train_labels)\n",
    "get_top_five_naive_bayes_words(phy_spam, phy_nonspam, p_x_spam, p_x_nonspam, train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdc6aca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9860c7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1b024e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8534ad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c871a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34721184",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
